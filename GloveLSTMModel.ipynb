{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ69pAC5fHeK"
   },
   "source": [
    "# **Setup** (run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FL_PeLcEb7B-",
    "outputId": "54175b27-d747-4740-fdd9-1777ce608b59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-08 16:58:04--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2023-11-08 16:58:05--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2023-11-08 16:58:07--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip.1’\n",
      "\n",
      "glove.6B.zip.1      100%[===================>] 822.24M  2.87MB/s    in 2m 49s  \n",
      "\n",
      "2023-11-08 17:00:58 (4.87 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "wy4Kl0ZRcnPS"
   },
   "outputs": [],
   "source": [
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQuCxqSpfR_a"
   },
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FXoWhEcIcx6r"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TextVectorization\n",
    "import os\n",
    "import pathlib\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD3ZJ1fleZfm"
   },
   "source": [
    "## **1. Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_g3Tp5XH5UpL",
    "outputId": "15f81d7a-c89a-4978-da5e-bf8f3ea655e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\n",
      "17329808/17329808 [==============================] - 28s 2us/step\n",
      "Number of directories: 20\n",
      "Directory names: ['talk.politics.mideast', 'rec.autos', 'comp.sys.mac.hardware', 'alt.atheism', 'rec.sport.baseball', 'comp.os.ms-windows.misc', 'rec.sport.hockey', 'sci.crypt', 'sci.med', 'talk.politics.misc', 'rec.motorcycles', 'comp.windows.x', 'comp.graphics', 'comp.sys.ibm.pc.hardware', 'sci.electronics', 'talk.politics.guns', 'sci.space', 'soc.religion.christian', 'misc.forsale', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "# Retrieve 20NewsGroup dataset\n",
    "data_path = keras.utils.get_file(\n",
    "    \"news20.tar.gz\",\n",
    "    \"http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/news20.tar.gz\",\n",
    "    untar=True,\n",
    ")\n",
    "\n",
    "data_dir = pathlib.Path(data_path).parent / \"20_newsgroup\"\n",
    "dirnames = os.listdir(data_dir)\n",
    "fnames = os.listdir(data_dir / \"comp.graphics\")\n",
    "\n",
    "print(\"Number of directories:\", len(dirnames))\n",
    "print(\"Directory names:\", dirnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "woOzSWD1eg8S"
   },
   "source": [
    "## **2. Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-8Rte6uH51wV",
    "outputId": "092420ff-2051-4321-e725-6e0327ef2a11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing alt.atheism, 1000 files found\n",
      "Processing comp.graphics, 1000 files found\n",
      "Processing comp.os.ms-windows.misc, 1000 files found\n",
      "Processing comp.sys.ibm.pc.hardware, 1000 files found\n",
      "Processing comp.sys.mac.hardware, 1000 files found\n",
      "Processing comp.windows.x, 1000 files found\n",
      "Processing misc.forsale, 1000 files found\n",
      "Processing rec.autos, 1000 files found\n",
      "Processing rec.motorcycles, 1000 files found\n",
      "Processing rec.sport.baseball, 1000 files found\n",
      "Processing rec.sport.hockey, 1000 files found\n",
      "Processing sci.crypt, 1000 files found\n",
      "Processing sci.electronics, 1000 files found\n",
      "Processing sci.med, 1000 files found\n",
      "Processing sci.space, 1000 files found\n",
      "Processing soc.religion.christian, 997 files found\n",
      "Processing talk.politics.guns, 1000 files found\n",
      "Processing talk.politics.mideast, 1000 files found\n",
      "Processing talk.politics.misc, 1000 files found\n",
      "Processing talk.religion.misc, 1000 files found\n",
      "Classes: ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "Number of samples: 19997\n"
     ]
    }
   ],
   "source": [
    "# Data Pre-Processing\n",
    "samples = []\n",
    "labels = []\n",
    "class_names = []\n",
    "class_index = 0\n",
    "for dirname in sorted(os.listdir(data_dir)):\n",
    "    class_names.append(dirname)\n",
    "    dirpath = data_dir / dirname\n",
    "    fnames = os.listdir(dirpath)\n",
    "    print(\"Processing %s, %d files found\" % (dirname, len(fnames)))\n",
    "    for fname in fnames:\n",
    "        fpath = dirpath / fname\n",
    "        f = open(fpath, encoding=\"latin-1\")\n",
    "        content = f.read()\n",
    "        lines = content.split(\"\\n\")\n",
    "        lines = lines[10:]\n",
    "        content = \"\\n\".join(lines)\n",
    "        samples.append(content)\n",
    "        labels.append(class_index)\n",
    "    class_index += 1\n",
    "\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Number of samples:\", len(samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "A96JXYHOQnaZ"
   },
   "outputs": [],
   "source": [
    "# Create train and test sets\n",
    "# Shuffle the data\n",
    "seed = 1337\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "validation_split = 0.2\n",
    "num_validation_samples = int(validation_split * len(samples))\n",
    "train_samples = samples[:-num_validation_samples]\n",
    "val_samples = samples[-num_validation_samples:]\n",
    "train_labels = labels[:-num_validation_samples]\n",
    "val_labels = labels[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "fprQ80zwLGAF"
   },
   "outputs": [],
   "source": [
    "# Model Constants\n",
    "DIMENSIONAL_LSTM_SIZE = 256\n",
    "MAX_NUM_WORDS = 20000 # placeholder -- can just make this the size of input data\n",
    "ENCODED_VECTOR_SIZE = 100 # 50, 100, 200, 300\n",
    "MAX_SEQUENCE_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMqCcvWueuoD"
   },
   "source": [
    "## **3. Data Vectorization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tVuCAZYnP_Yz"
   },
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "vectorizer = TextVectorization(max_tokens = MAX_NUM_WORDS, output_sequence_length = MAX_SEQUENCE_LENGTH)\n",
    "text_ds = tf.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)\n",
    "\n",
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUZaIgiCe0ud"
   },
   "source": [
    "## **4. Pre-Trained Embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cwwi-9f1Sh0X",
    "outputId": "0bf3d17f-29c3-4490-a19d-c974af5ff44b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#Load pre-trained word embeddings\n",
    "path_to_glove_file =  \"glove.6B.100d.txt\"\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GR3huZWe67K",
    "outputId": "81990ab5-de81-4d3e-8afb-239f62406510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 17999 words (2001 misses)\n"
     ]
    }
   ],
   "source": [
    "# Embedding Matrix\n",
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Q_AM727e8cI"
   },
   "source": [
    "# **5. Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJItqLsZ565O",
    "outputId": "5571410b-bdf4-4b24-9e24-7e08ed8a0070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 100)         2000200   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256)               365568    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                5140      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2370908 (9.04 MB)\n",
      "Trainable params: 370708 (1.41 MB)\n",
      "Non-trainable params: 2000200 (7.63 MB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# LSTM Model\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(num_tokens, ENCODED_VECTOR_SIZE, embeddings_initializer=keras.initializers.Constant(embedding_matrix),trainable=False))\n",
    "model.add(LSTM(DIMENSIONAL_LSTM_SIZE))\n",
    "model.add(Dense(len(class_names), activation='sigmoid'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\", metrics=[\"acc\"])\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy\n",
    "model.add(Dropout(0.3))\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu1nZ_MsfBox"
   },
   "source": [
    "## **6. Model Training + Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "iSKb7tFvfGCk"
   },
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_val = vectorizer(np.array([[s] for s in val_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_val = np.array(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Rhgv8bm4ku3X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "125/125 [==============================] - 97s 767ms/step - loss: 2.8857 - acc: 0.1030 - val_loss: 2.6048 - val_acc: 0.1290\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 92s 740ms/step - loss: 2.7272 - acc: 0.1401 - val_loss: 3.0020 - val_acc: 0.1010\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 90s 722ms/step - loss: 2.5574 - acc: 0.1794 - val_loss: 3.1031 - val_acc: 0.1190\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 92s 738ms/step - loss: 2.5888 - acc: 0.1775 - val_loss: 2.6469 - val_acc: 0.1558\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 104s 831ms/step - loss: 2.4982 - acc: 0.1888 - val_loss: 2.5934 - val_acc: 0.1785\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 97s 775ms/step - loss: 2.3267 - acc: 0.2411 - val_loss: 2.4476 - val_acc: 0.2011\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 96s 764ms/step - loss: 2.1386 - acc: 0.2835 - val_loss: 2.1217 - val_acc: 0.2646\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 91s 730ms/step - loss: 2.0879 - acc: 0.3079 - val_loss: 1.9330 - val_acc: 0.3421\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 91s 726ms/step - loss: 1.8580 - acc: 0.3859 - val_loss: 1.7650 - val_acc: 0.4196\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 90s 718ms/step - loss: 1.6574 - acc: 0.4466 - val_loss: 1.5878 - val_acc: 0.4639\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 93s 741ms/step - loss: 1.5182 - acc: 0.4971 - val_loss: 1.4773 - val_acc: 0.4856\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 91s 728ms/step - loss: 1.3758 - acc: 0.5421 - val_loss: 1.4035 - val_acc: 0.5411\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 94s 753ms/step - loss: 1.2888 - acc: 0.5766 - val_loss: 1.2972 - val_acc: 0.5641\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 101s 804ms/step - loss: 1.2193 - acc: 0.5983 - val_loss: 1.2568 - val_acc: 0.5886\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 94s 750ms/step - loss: 1.1128 - acc: 0.6318 - val_loss: 1.1983 - val_acc: 0.6047\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 121s 972ms/step - loss: 1.0565 - acc: 0.6511 - val_loss: 1.1592 - val_acc: 0.6209\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 102s 817ms/step - loss: 1.0187 - acc: 0.6670 - val_loss: 1.1350 - val_acc: 0.6322\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 103s 824ms/step - loss: 0.9651 - acc: 0.6798 - val_loss: 1.0575 - val_acc: 0.6504\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 111s 886ms/step - loss: 0.8932 - acc: 0.7075 - val_loss: 1.0526 - val_acc: 0.6617\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 109s 862ms/step - loss: 0.8525 - acc: 0.7188 - val_loss: 1.0227 - val_acc: 0.6697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2877dd8d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=20, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
