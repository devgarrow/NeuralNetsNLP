{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0955ac01-5912-4880-be91-7a220498de40",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Data Pre-Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46ac8db8-5bcf-47ec-8d0c-93dd60f8847e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98f36ed5-f22e-4ee9-8e3f-7f760b988834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a list of stopwords\n",
    "stopwords = {\n",
    "    'the', 'and', 'is', 'in', 'to', 'of', 'it', 'you', 'that', 'a', 'i', 'for', 'on', 'with', 'this',\n",
    "    'as', 'have', 'but', 'not', 'be'\n",
    "}\n",
    "\n",
    "# Other unused stopwords - can be added into stopwords as seen fit\n",
    "other_stopwords = {\n",
    "    'were', 'then', \"needn't\", \"wasn't\", 'isn', 'just', 'we', 'yourselves', 'more', 'herself', 'wouldn',\n",
    "    'aren', \"mightn't\", 'did', 'don', 'ma', \"haven't\", 'its', 'only', 'too', 'd', \"hasn't\", 'was', 'myself',\n",
    "    'shan', 'other', 'our', 'again', 'each', 'yours', 'me', 'some', 'themselves', 'why', 'than', 'do', 'weren',\n",
    "    'been', 'few', 'having', \"she's\", 'who', \"you're\", 'over', \"isn't\", 'nor', 'am', 'doesn', 'below', \"shan't\",\n",
    "    'does', 'so', 'y', \"that'll\", 'haven', 'mustn', 'these', 'm', 'him', 'are', 'those', 'out', 'most', \"you'll\",\n",
    "    'under', 't', 'has', 'up', 'should', 'both', 'no', 'he', 'hadn', 're', 'yourself', 'an', 'during', 'until',\n",
    "    'between', \"don't\", 'into', \"didn't\", 'here', 'shouldn', 'ain', 'll', 'hers', \"weren't\", 'wasn', 'couldn',\n",
    "    'which', \"couldn't\", 'their', 'where', 'how', 'whom', 'same', 'or', 'can', 'didn', 'while', 'at', \"hadn't\",\n",
    "    'own', 'needn', 'before', 'such', 'because', 'from', 'if', 'itself', 'after', 'ourselves', \"it's\", \"should've\",\n",
    "    'mightn', \"mustn't\", 'theirs', 'when', 'all', 'about', 'will', 'being', 'above', 'ours', 'them', 'her', 'there',\n",
    "    'very', 'hasn', 'down', 'further', \"won't\", 'his', 'what', 'doing', 'any', \"you've\", 'now', 'they', 'won', \n",
    "    'your', 'through', \"aren't\", 'she', 'my'\n",
    "}\n",
    "\n",
    "\n",
    "# Define regexps\n",
    "contractions_re = re.compile(r\"'|-|\\.|!\")\n",
    "symbols_re = re.compile(r\"[^A-Za-z0-9\\s]\")\n",
    "spaces_re = re.compile(r\"\\s+\")\n",
    "\n",
    "# Define dictionary for contraction replacements\n",
    "contractions_dict = {\n",
    "    \"what's\": \"what is\",\n",
    "    \"n't\": \" not\",\n",
    "    \"i'm\": \"i am\", \n",
    "    \"'re\": \" are\",\n",
    "    \"'ve\": \" have\", \n",
    "    \"'d\": \" would\",\n",
    "    \"'ll\": \" will\"\n",
    "}\n",
    "\n",
    "# Instantiate stemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preprocess(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove contractions\n",
    "    text = contractions_re.sub(lambda match: contractions_dict.get(match.group(0), match.group(0)), text)\n",
    "\n",
    "    # Remove punctuation and symbols\n",
    "    text = symbols_re.sub(\" \", text)\n",
    "\n",
    "    # Remove stopwords and stem words\n",
    "    # TODO: Decision about adding stemming? Results in suffixes and prefixes being removed (e.g. device becomes devic)\n",
    "    # text = \" \".join([stemmer.stem(word) for word in text.split() if word not in stop_words])\n",
    "\n",
    "    # Remove extra spaces\n",
    "    text = spaces_re.sub(\" \", text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    # Split text into tokens\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdc9ade4-34cb-4bbc-97b7-929be0d8305f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load in dataset\n",
    "# TODO: Do we need quotes?\n",
    "# dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers'))\n",
    "dataset = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "samples = dataset.data\n",
    "labels = dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "792a89ba-d049-4771-8f41-bf39c7cd2323",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocess samples\n",
    "preprocessed_samples = [preprocess(sample) for sample in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3a17080d-8b64-4b6b-ad65-969e09521fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tokenize and vectorize data\n",
    "vectorizer = TfidfVectorizer(tokenizer=tokenize)\n",
    "vectors = vectorizer.fit_transform(preprocessed_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cecbb94b-2503-46ae-803d-385d8c556548",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sample:\n",
      " \n",
      "Think!\n",
      "\n",
      "It's the SCSI card doing the DMA transfers NOT the disks...\n",
      "\n",
      "The SCSI card can do DMA transfers containing data from any of the SCSI devices\n",
      "it is attached when it wants to.\n",
      "\n",
      "An important feature of SCSI is the ability to detach a device. This frees the\n",
      "SCSI bus for other devices. This is typically used in a multi-tasking OS to\n",
      "start transfers on several devices. While each device is seeking the data the\n",
      "bus is free for other commands and data transfers. When the devices are\n",
      "ready to transfer the data they can aquire the bus and send the data.\n",
      "\n",
      "On an IDE bus when you start a transfer the bus is busy until the disk has seeked\n",
      "the data and transfered it. This is typically a 10-20ms second lock out for other\n",
      "processes wanting the bus irrespective of transfer time.\n",
      "\n",
      "\n",
      "Preprocessed sample:\n",
      " think it s the scsi card doing the dma transfers not the disks the scsi card can do dma transfers containing data from any of the scsi devices it is attached when it wants to an important feature of scsi is the ability to detach a device this frees the scsi bus for other devices this is typically used in a multi tasking os to start transfers on several devices while each device is seeking the data the bus is free for other commands and data transfers when the devices are ready to transfer the data they can aquire the bus and send the data on an ide bus when you start a transfer the bus is busy until the disk has seeked the data and transfered it this is typically a 10 20ms second lock out for other processes wanting the bus irrespective of transfer time\n",
      "\n",
      "Tokenized sample:\n",
      " ['think', 'it', 's', 'the', 'scsi', 'card', 'doing', 'the', 'dma', 'transfers', 'not', 'the', 'disks', 'the', 'scsi', 'card', 'can', 'do', 'dma', 'transfers', 'containing', 'data', 'from', 'any', 'of', 'the', 'scsi', 'devices', 'it', 'is', 'attached', 'when', 'it', 'wants', 'to', 'an', 'important', 'feature', 'of', 'scsi', 'is', 'the', 'ability', 'to', 'detach', 'a', 'device', 'this', 'frees', 'the', 'scsi', 'bus', 'for', 'other', 'devices', 'this', 'is', 'typically', 'used', 'in', 'a', 'multi', 'tasking', 'os', 'to', 'start', 'transfers', 'on', 'several', 'devices', 'while', 'each', 'device', 'is', 'seeking', 'the', 'data', 'the', 'bus', 'is', 'free', 'for', 'other', 'commands', 'and', 'data', 'transfers', 'when', 'the', 'devices', 'are', 'ready', 'to', 'transfer', 'the', 'data', 'they', 'can', 'aquire', 'the', 'bus', 'and', 'send', 'the', 'data', 'on', 'an', 'ide', 'bus', 'when', 'you', 'start', 'a', 'transfer', 'the', 'bus', 'is', 'busy', 'until', 'the', 'disk', 'has', 'seeked', 'the', 'data', 'and', 'transfered', 'it', 'this', 'is', 'typically', 'a', '10', '20ms', 'second', 'lock', 'out', 'for', 'other', 'processes', 'wanting', 'the', 'bus', 'irrespective', 'of', 'transfer', 'time']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original sample:\\n\", samples[3])\n",
    "print(\"\\nPreprocessed sample:\\n\", preprocessed_samples[3])\n",
    "print(\"\\nTokenized sample:\\n\", tokenized_samples[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
